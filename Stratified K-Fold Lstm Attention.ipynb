{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e154a47bf09b8770980486e87786317a1b3038e1"
   },
   "source": [
    "Inspired from Bruno Aquino's Kernel:\n",
    "https://www.kaggle.com/braquino/5-fold-lstm-attention-fully-commented-0-694\n",
    "\n",
    "I am using early stopping on the 5 Folds Stratified K Folds.\n",
    "\n",
    "Updates : Removed Early Stopping and Batch Normalization because of lower accuracy. Included Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq # Used to read the data\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm # Processing time measurement\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,RepeatedStratifiedKFold # Used to use Kfold to train our model\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6e6379386e44afc69bee8895a52da22199e888fb"
   },
   "outputs": [],
   "source": [
    "# select how many folds will be created\n",
    "N_SPLITS = 5\n",
    "# it is just a constant with the measurements data size\n",
    "sample_size = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c3340ee96becb5ca8f075d9c44b7df383ddba5ee"
   },
   "outputs": [],
   "source": [
    "# It is the official metric used in this competition\n",
    "# below is the declaration of a function used inside the keras model, calculation with K (keras backend / thensorflow)\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n",
    "    y_true = tf.convert_to_tensor(y_true, np.float32)\n",
    "    \n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "eda7ea366117d1ce8e5fce69e5bba333821d8b48"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "0              0              0       0\n",
       "               1              1       0\n",
       "               2              2       0\n",
       "1              0              3       1\n",
       "               1              4       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just load train data\n",
    "df_train = pd.read_csv('../input/metadata_train.csv')\n",
    "# set index, it makes the data access much faster\n",
    "df_train = df_train.set_index(['id_measurement', 'phase'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "26df6c7fbfecd537404866faec13d1238ae3ebc6"
   },
   "outputs": [],
   "source": [
    "# in other notebook I have extracted the min and max values from the train data, the measurements\n",
    "max_num = 127\n",
    "min_num = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7b0717b14bcfcba1f48d33c8161ae51c778687af"
   },
   "outputs": [],
   "source": [
    "# This function standardize the data from (-128 to 127) to (-1 to 1)\n",
    "# Theoretically it helps in the NN Model training, but I didn't tested without it\n",
    "def min_max_transformation(ts, min_data, max_data, range_needed=(-1,1)):\n",
    "    if min_data < 0:\n",
    "        ts_std = (ts + abs(min_data)) / (max_data + abs(min_data))\n",
    "    else:\n",
    "        ts_std = (ts - min_data) / (max_data - min_data)\n",
    "    if range_needed[0] < 0:    \n",
    "        return ts_std * (range_needed[1] + abs(range_needed[0])) + range_needed[0]\n",
    "    else:\n",
    "        return ts_std * (range_needed[1] - range_needed[0]) + range_needed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c6137bbbe75c3a1509a5f98e08805dbbd492aa37"
   },
   "outputs": [],
   "source": [
    "def transform_ts(ts, n_dim=160, min_max=(-1,1)):\n",
    "    # convert data into -1 to 1\n",
    "    ts_std = min_max_transformation(ts, min_data=min_num, max_data=max_num)\n",
    "    # bucket or chunk size, 5000 in this case (800000 / 160)\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    # new_ts will be the container of the new data\n",
    "    new_ts = []\n",
    "    # this for iteract any chunk/bucket until reach the whole sample_size (800000)\n",
    "    for i in range(0, sample_size, bucket_size):\n",
    "        # cut each bucket to ts_range\n",
    "        ts_range = ts_std[i:i + bucket_size]\n",
    "        # calculate each feature\n",
    "        mean = ts_range.mean()\n",
    "        std = ts_range.std() # standard deviation\n",
    "        std_top = mean + std # I have to test it more, but is is like a band\n",
    "        std_bot = mean - std\n",
    "        # I think that the percentiles are very important, it is like a distribuiton analysis from eath chunk\n",
    "        percentil_calc = np.percentile(ts_range, [0, 1, 25, 50, 75, 99, 100]) \n",
    "        max_range = percentil_calc[-1] - percentil_calc[0] # this is the amplitude of the chunk\n",
    "        relative_percentile = percentil_calc - mean # maybe it could heap to understand the asymmetry\n",
    "        new_ts.append(np.concatenate([np.asarray([mean, std, std_top, std_bot, max_range]),percentil_calc, relative_percentile]))\n",
    "    return np.asarray(new_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7460e718a605803f1d9e4fbec61750a0deb02a47"
   },
   "outputs": [],
   "source": [
    "# this function take a piece of data and convert using transform_ts(), but it does to each of the 3 phases\n",
    "# if we would try to do in one time, could exceed the RAM Memmory\n",
    "def prepare_data(start, end):\n",
    "\n",
    "    praq_train = pq.read_pandas('../input/train.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    X = []\n",
    "    y = []\n",
    "   \n",
    "    for id_measurement in tqdm(df_train.index.levels[0].unique()[int(start/3):int(end/3)]):\n",
    "        X_signal = []\n",
    "        # for each phase of the signal\n",
    "        for phase in [0,1,2]:\n",
    "            # extract from df_train both signal_id and target to compose the new data sets\n",
    "            signal_id, target = df_train.loc[id_measurement].loc[phase]\n",
    "            # but just append the target one time, to not triplicate it\n",
    "            if phase == 0:\n",
    "                y.append(target)\n",
    "            # extract and transform data into sets of features\n",
    "            X_signal.append(transform_ts(praq_train[str(signal_id)]))\n",
    "        # concatenate all the 3 phases in one matrix\n",
    "        X_signal = np.concatenate(X_signal, axis=1)\n",
    "        # add the data to X\n",
    "        X.append(X_signal)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "52dc826ab9ee1dd56c9fb29bd5c1b2d26b5928bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1452/1452 [05:34<00:00,  4.38it/s]\n",
      "100%|██████████| 1452/1452 [05:34<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# this code is very simple, divide the total size of the df_train into two sets and process it\n",
    "X = []\n",
    "y = []\n",
    "def load_all():\n",
    "    total_size = len(df_train)\n",
    "    for ini, end in [(0, int(total_size/2)), (int(total_size/2), total_size)]:\n",
    "        X_temp, y_temp = prepare_data(ini, end)\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "load_all()\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "51ad0e25b00536de6170168499923d82ae1d735f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 160, 57) (2904,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "# save data into file, a numpy specific format\n",
    "np.save(\"X.npy\",X)\n",
    "np.save(\"y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "289bc7d1ab8048a60025801b457f8df1d848acbc"
   },
   "outputs": [],
   "source": [
    "# This is NN LSTM Model creation\n",
    "def model_lstm(input_shape):\n",
    "    # The shape was explained above, must have this order\n",
    "    inp = Input(shape=(input_shape[1], input_shape[2],))\n",
    "    \n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(inp)\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    \n",
    "    x = Attention(input_shape[1])(x)\n",
    "   \n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[matthews_correlation])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "8d6f4ca319c383b1b4f671a37c5a324136e7a466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fold 1\n",
      "Train on 2322 samples, validate on 582 samples\n",
      "Epoch 1/40\n",
      "2322/2322 [==============================] - 4s 2ms/step - loss: 0.3631 - matthews_correlation: 0.0047 - val_loss: 0.2391 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_0.h5\n",
      "Epoch 2/40\n",
      "2322/2322 [==============================] - 1s 482us/step - loss: 0.2318 - matthews_correlation: 0.0000e+00 - val_loss: 0.2353 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/40\n",
      "2322/2322 [==============================] - 1s 485us/step - loss: 0.2287 - matthews_correlation: 0.0000e+00 - val_loss: 0.2285 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/40\n",
      "2322/2322 [==============================] - 1s 485us/step - loss: 0.2238 - matthews_correlation: 0.0000e+00 - val_loss: 0.2162 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/40\n",
      "2322/2322 [==============================] - 1s 482us/step - loss: 0.2115 - matthews_correlation: 0.0000e+00 - val_loss: 0.2066 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/40\n",
      "2322/2322 [==============================] - 1s 485us/step - loss: 0.2105 - matthews_correlation: 0.0000e+00 - val_loss: 0.1914 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/40\n",
      "2322/2322 [==============================] - 1s 482us/step - loss: 0.1813 - matthews_correlation: 0.1493 - val_loss: 0.1794 - val_matthews_correlation: 0.2855\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.00000 to 0.28552, saving model to weights_0.h5\n",
      "Epoch 8/40\n",
      "2322/2322 [==============================] - 1s 480us/step - loss: 0.1890 - matthews_correlation: 0.1122 - val_loss: 0.2027 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.28552\n",
      "Epoch 9/40\n",
      "2322/2322 [==============================] - 1s 482us/step - loss: 0.1858 - matthews_correlation: 0.0827 - val_loss: 0.2067 - val_matthews_correlation: 0.4032\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.28552 to 0.40320, saving model to weights_0.h5\n",
      "Epoch 10/40\n",
      "2322/2322 [==============================] - 1s 481us/step - loss: 0.1547 - matthews_correlation: 0.2986 - val_loss: 0.1443 - val_matthews_correlation: 0.4662\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.40320 to 0.46620, saving model to weights_0.h5\n",
      "Epoch 11/40\n",
      "2322/2322 [==============================] - 1s 484us/step - loss: 0.1450 - matthews_correlation: 0.4562 - val_loss: 0.1166 - val_matthews_correlation: 0.5256\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.46620 to 0.52561, saving model to weights_0.h5\n",
      "Epoch 12/40\n",
      "2322/2322 [==============================] - 1s 481us/step - loss: 0.1258 - matthews_correlation: 0.5402 - val_loss: 0.1279 - val_matthews_correlation: 0.5330\n",
      "\n",
      "Epoch 00012: val_matthews_correlation improved from 0.52561 to 0.53296, saving model to weights_0.h5\n",
      "Epoch 13/40\n",
      "2322/2322 [==============================] - 1s 485us/step - loss: 0.1106 - matthews_correlation: 0.6683 - val_loss: 0.1170 - val_matthews_correlation: 0.5545\n",
      "\n",
      "Epoch 00013: val_matthews_correlation improved from 0.53296 to 0.55455, saving model to weights_0.h5\n",
      "Epoch 14/40\n",
      "2322/2322 [==============================] - 1s 482us/step - loss: 0.1116 - matthews_correlation: 0.6602 - val_loss: 0.1171 - val_matthews_correlation: 0.5549\n",
      "\n",
      "Epoch 00014: val_matthews_correlation improved from 0.55455 to 0.55492, saving model to weights_0.h5\n",
      "Epoch 15/40\n",
      "2322/2322 [==============================] - 1s 444us/step - loss: 0.1115 - matthews_correlation: 0.6353 - val_loss: 0.1168 - val_matthews_correlation: 0.5519\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.55492\n",
      "Epoch 16/40\n",
      "2322/2322 [==============================] - 1s 440us/step - loss: 0.1056 - matthews_correlation: 0.6308 - val_loss: 0.1147 - val_matthews_correlation: 0.5796\n",
      "\n",
      "Epoch 00016: val_matthews_correlation improved from 0.55492 to 0.57962, saving model to weights_0.h5\n",
      "Epoch 17/40\n",
      "2322/2322 [==============================] - 1s 443us/step - loss: 0.0993 - matthews_correlation: 0.6510 - val_loss: 0.1175 - val_matthews_correlation: 0.5694\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.57962\n",
      "Epoch 18/40\n",
      "2322/2322 [==============================] - 1s 441us/step - loss: 0.0974 - matthews_correlation: 0.6931 - val_loss: 0.1121 - val_matthews_correlation: 0.5868\n",
      "\n",
      "Epoch 00018: val_matthews_correlation improved from 0.57962 to 0.58682, saving model to weights_0.h5\n",
      "Epoch 19/40\n",
      "2322/2322 [==============================] - 1s 442us/step - loss: 0.1111 - matthews_correlation: 0.6576 - val_loss: 0.1262 - val_matthews_correlation: 0.4770\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.58682\n",
      "Epoch 20/40\n",
      "2322/2322 [==============================] - 1s 442us/step - loss: 0.0950 - matthews_correlation: 0.6691 - val_loss: 0.1194 - val_matthews_correlation: 0.5549\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.58682\n",
      "Epoch 21/40\n",
      "2322/2322 [==============================] - 1s 441us/step - loss: 0.0920 - matthews_correlation: 0.7049 - val_loss: 0.1128 - val_matthews_correlation: 0.5788\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.58682\n",
      "Epoch 22/40\n",
      "2322/2322 [==============================] - 1s 441us/step - loss: 0.0992 - matthews_correlation: 0.6911 - val_loss: 0.1247 - val_matthews_correlation: 0.4747\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.58682\n",
      "Epoch 23/40\n",
      "2322/2322 [==============================] - 1s 443us/step - loss: 0.0941 - matthews_correlation: 0.6758 - val_loss: 0.1064 - val_matthews_correlation: 0.5953\n",
      "\n",
      "Epoch 00023: val_matthews_correlation improved from 0.58682 to 0.59531, saving model to weights_0.h5\n",
      "Epoch 24/40\n",
      "2322/2322 [==============================] - 1s 447us/step - loss: 0.0889 - matthews_correlation: 0.6855 - val_loss: 0.1152 - val_matthews_correlation: 0.4988\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 25/40\n",
      "2322/2322 [==============================] - 1s 484us/step - loss: 0.0930 - matthews_correlation: 0.6834 - val_loss: 0.1098 - val_matthews_correlation: 0.5811\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 26/40\n",
      "2322/2322 [==============================] - 1s 480us/step - loss: 0.0916 - matthews_correlation: 0.7105 - val_loss: 0.1174 - val_matthews_correlation: 0.5343\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 27/40\n",
      "2322/2322 [==============================] - 1s 483us/step - loss: 0.0926 - matthews_correlation: 0.6874 - val_loss: 0.1141 - val_matthews_correlation: 0.5811\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 28/40\n",
      "2322/2322 [==============================] - 1s 480us/step - loss: 0.0881 - matthews_correlation: 0.6814 - val_loss: 0.1139 - val_matthews_correlation: 0.5687\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 29/40\n",
      "2322/2322 [==============================] - 1s 481us/step - loss: 0.0918 - matthews_correlation: 0.6707 - val_loss: 0.1244 - val_matthews_correlation: 0.5204\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 30/40\n",
      "2322/2322 [==============================] - 1s 483us/step - loss: 0.0871 - matthews_correlation: 0.7003 - val_loss: 0.1197 - val_matthews_correlation: 0.5403\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 31/40\n",
      "2322/2322 [==============================] - 1s 484us/step - loss: 0.0973 - matthews_correlation: 0.6444 - val_loss: 0.1187 - val_matthews_correlation: 0.5655\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 32/40\n",
      "2322/2322 [==============================] - 1s 487us/step - loss: 0.0993 - matthews_correlation: 0.6367 - val_loss: 0.1137 - val_matthews_correlation: 0.5728\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 33/40\n",
      "2322/2322 [==============================] - 1s 484us/step - loss: 0.0892 - matthews_correlation: 0.7146 - val_loss: 0.1077 - val_matthews_correlation: 0.5822\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 34/40\n",
      "2322/2322 [==============================] - 1s 449us/step - loss: 0.0843 - matthews_correlation: 0.6960 - val_loss: 0.1147 - val_matthews_correlation: 0.5953\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 35/40\n",
      "2322/2322 [==============================] - 1s 441us/step - loss: 0.0873 - matthews_correlation: 0.6724 - val_loss: 0.1127 - val_matthews_correlation: 0.5360\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 36/40\n",
      "2322/2322 [==============================] - 1s 441us/step - loss: 0.0875 - matthews_correlation: 0.6647 - val_loss: 0.1194 - val_matthews_correlation: 0.5473\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 37/40\n",
      "2322/2322 [==============================] - 1s 439us/step - loss: 0.0871 - matthews_correlation: 0.6887 - val_loss: 0.1238 - val_matthews_correlation: 0.5186\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 38/40\n",
      "2322/2322 [==============================] - 1s 438us/step - loss: 0.0938 - matthews_correlation: 0.6437 - val_loss: 0.1062 - val_matthews_correlation: 0.5689\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.59531\n",
      "Epoch 39/40\n",
      "2322/2322 [==============================] - 1s 444us/step - loss: 0.0912 - matthews_correlation: 0.6908 - val_loss: 0.1225 - val_matthews_correlation: 0.6035\n",
      "\n",
      "Epoch 00039: val_matthews_correlation improved from 0.59531 to 0.60353, saving model to weights_0.h5\n",
      "Epoch 40/40\n",
      "2322/2322 [==============================] - 1s 442us/step - loss: 0.0954 - matthews_correlation: 0.7117 - val_loss: 0.1234 - val_matthews_correlation: 0.5235\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.60353\n",
      "Beginning fold 2\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/40\n",
      "2323/2323 [==============================] - 2s 979us/step - loss: 0.3641 - matthews_correlation: 0.0000e+00 - val_loss: 0.2727 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_1.h5\n",
      "Epoch 2/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.2390 - matthews_correlation: 0.0000e+00 - val_loss: 0.2294 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.2265 - matthews_correlation: 0.0000e+00 - val_loss: 0.2235 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.2145 - matthews_correlation: 0.0000e+00 - val_loss: 0.2427 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.2130 - matthews_correlation: 0.0000e+00 - val_loss: 0.2076 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.2030 - matthews_correlation: 0.1081 - val_loss: 0.2109 - val_matthews_correlation: 0.1088\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.00000 to 0.10885, saving model to weights_1.h5\n",
      "Epoch 7/40\n",
      "2323/2323 [==============================] - 1s 480us/step - loss: 0.1991 - matthews_correlation: 0.0996 - val_loss: 0.1879 - val_matthews_correlation: 0.1638\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.10885 to 0.16377, saving model to weights_1.h5\n",
      "Epoch 8/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.1774 - matthews_correlation: 0.2857 - val_loss: 0.1871 - val_matthews_correlation: 0.2964\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.16377 to 0.29645, saving model to weights_1.h5\n",
      "Epoch 9/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.1389 - matthews_correlation: 0.3999 - val_loss: 0.1577 - val_matthews_correlation: 0.3989\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.29645 to 0.39889, saving model to weights_1.h5\n",
      "Epoch 10/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.1347 - matthews_correlation: 0.5319 - val_loss: 0.1369 - val_matthews_correlation: 0.5950\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.39889 to 0.59501, saving model to weights_1.h5\n",
      "Epoch 11/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.1112 - matthews_correlation: 0.6511 - val_loss: 0.1540 - val_matthews_correlation: 0.4713\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 12/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.1020 - matthews_correlation: 0.6560 - val_loss: 0.1268 - val_matthews_correlation: 0.5466\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 13/40\n",
      "2323/2323 [==============================] - 1s 479us/step - loss: 0.0962 - matthews_correlation: 0.6722 - val_loss: 0.1325 - val_matthews_correlation: 0.5756\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 14/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0998 - matthews_correlation: 0.6530 - val_loss: 0.1407 - val_matthews_correlation: 0.4069\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 15/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0960 - matthews_correlation: 0.6809 - val_loss: 0.1281 - val_matthews_correlation: 0.5890\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 16/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.0954 - matthews_correlation: 0.6820 - val_loss: 0.1345 - val_matthews_correlation: 0.5075\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 17/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.0958 - matthews_correlation: 0.6938 - val_loss: 0.1540 - val_matthews_correlation: 0.4903\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 18/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.1056 - matthews_correlation: 0.6218 - val_loss: 0.1300 - val_matthews_correlation: 0.5212\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 19/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0910 - matthews_correlation: 0.7234 - val_loss: 0.1273 - val_matthews_correlation: 0.5357\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 20/40\n",
      "2323/2323 [==============================] - 1s 480us/step - loss: 0.0948 - matthews_correlation: 0.6623 - val_loss: 0.1250 - val_matthews_correlation: 0.5327\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 21/40\n",
      "2323/2323 [==============================] - 1s 480us/step - loss: 0.1011 - matthews_correlation: 0.6272 - val_loss: 0.1471 - val_matthews_correlation: 0.4671\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 22/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0915 - matthews_correlation: 0.6657 - val_loss: 0.1267 - val_matthews_correlation: 0.5324\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 23/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0871 - matthews_correlation: 0.7138 - val_loss: 0.1256 - val_matthews_correlation: 0.5851\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 24/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.0913 - matthews_correlation: 0.7141 - val_loss: 0.1243 - val_matthews_correlation: 0.5621\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 25/40\n",
      "2323/2323 [==============================] - 1s 480us/step - loss: 0.0940 - matthews_correlation: 0.6374 - val_loss: 0.1281 - val_matthews_correlation: 0.5388\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 26/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.0924 - matthews_correlation: 0.6984 - val_loss: 0.1204 - val_matthews_correlation: 0.5936\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 27/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.1007 - matthews_correlation: 0.6939 - val_loss: 0.1227 - val_matthews_correlation: 0.5746\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.59501\n",
      "Epoch 28/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0887 - matthews_correlation: 0.7136 - val_loss: 0.1221 - val_matthews_correlation: 0.5976\n",
      "\n",
      "Epoch 00028: val_matthews_correlation improved from 0.59501 to 0.59759, saving model to weights_1.h5\n",
      "Epoch 29/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.0875 - matthews_correlation: 0.6997 - val_loss: 0.1212 - val_matthews_correlation: 0.5161\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 30/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0888 - matthews_correlation: 0.6516 - val_loss: 0.1244 - val_matthews_correlation: 0.5656\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 31/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.0919 - matthews_correlation: 0.6859 - val_loss: 0.1248 - val_matthews_correlation: 0.3920\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 32/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0875 - matthews_correlation: 0.6855 - val_loss: 0.1279 - val_matthews_correlation: 0.5748\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 33/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0846 - matthews_correlation: 0.7220 - val_loss: 0.1241 - val_matthews_correlation: 0.5598\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 34/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.0848 - matthews_correlation: 0.7080 - val_loss: 0.1216 - val_matthews_correlation: 0.5089\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 35/40\n",
      "2323/2323 [==============================] - 1s 487us/step - loss: 0.0926 - matthews_correlation: 0.7127 - val_loss: 0.1259 - val_matthews_correlation: 0.5380\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 36/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.0867 - matthews_correlation: 0.6569 - val_loss: 0.1214 - val_matthews_correlation: 0.4309\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 37/40\n",
      "2323/2323 [==============================] - 1s 481us/step - loss: 0.0908 - matthews_correlation: 0.6756 - val_loss: 0.1550 - val_matthews_correlation: 0.4288\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 38/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0915 - matthews_correlation: 0.6284 - val_loss: 0.1352 - val_matthews_correlation: 0.4558\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 39/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.0797 - matthews_correlation: 0.7438 - val_loss: 0.1258 - val_matthews_correlation: 0.5309\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.59759\n",
      "Epoch 40/40\n",
      "2323/2323 [==============================] - 1s 479us/step - loss: 0.0798 - matthews_correlation: 0.7596 - val_loss: 0.1307 - val_matthews_correlation: 0.5071\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.59759\n",
      "Beginning fold 3\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/40\n",
      "2323/2323 [==============================] - 2s 939us/step - loss: 0.3487 - matthews_correlation: 0.0000e+00 - val_loss: 0.2310 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_2.h5\n",
      "Epoch 2/40\n",
      "2323/2323 [==============================] - 1s 442us/step - loss: 0.2294 - matthews_correlation: 0.0000e+00 - val_loss: 0.2226 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/40\n",
      "2323/2323 [==============================] - 1s 437us/step - loss: 0.2207 - matthews_correlation: 0.0000e+00 - val_loss: 0.2245 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/40\n",
      "2323/2323 [==============================] - 1s 439us/step - loss: 0.2171 - matthews_correlation: 0.0000e+00 - val_loss: 0.2141 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/40\n",
      "2323/2323 [==============================] - 1s 438us/step - loss: 0.2034 - matthews_correlation: 0.0329 - val_loss: 0.2166 - val_matthews_correlation: 0.1178\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.00000 to 0.11783, saving model to weights_2.h5\n",
      "Epoch 6/40\n",
      "2323/2323 [==============================] - 1s 437us/step - loss: 0.1983 - matthews_correlation: 0.0575 - val_loss: 0.1842 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.11783\n",
      "Epoch 7/40\n",
      "2323/2323 [==============================] - 1s 439us/step - loss: 0.1745 - matthews_correlation: 0.0243 - val_loss: 0.1348 - val_matthews_correlation: 0.0934\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.11783\n",
      "Epoch 8/40\n",
      "2323/2323 [==============================] - 1s 438us/step - loss: 0.1308 - matthews_correlation: 0.3337 - val_loss: 0.2214 - val_matthews_correlation: 0.4738\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.11783 to 0.47376, saving model to weights_2.h5\n",
      "Epoch 9/40\n",
      "2323/2323 [==============================] - 1s 441us/step - loss: 0.1384 - matthews_correlation: 0.4858 - val_loss: 0.0929 - val_matthews_correlation: 0.6520\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.47376 to 0.65198, saving model to weights_2.h5\n",
      "Epoch 10/40\n",
      "2323/2323 [==============================] - 1s 434us/step - loss: 0.1216 - matthews_correlation: 0.4973 - val_loss: 0.1157 - val_matthews_correlation: 0.6389\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.65198\n",
      "Epoch 11/40\n",
      "2323/2323 [==============================] - 1s 463us/step - loss: 0.1206 - matthews_correlation: 0.5489 - val_loss: 0.0934 - val_matthews_correlation: 0.6353\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.65198\n",
      "Epoch 12/40\n",
      "2323/2323 [==============================] - 1s 479us/step - loss: 0.1127 - matthews_correlation: 0.6174 - val_loss: 0.1218 - val_matthews_correlation: 0.6646\n",
      "\n",
      "Epoch 00012: val_matthews_correlation improved from 0.65198 to 0.66459, saving model to weights_2.h5\n",
      "Epoch 13/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.1071 - matthews_correlation: 0.6318 - val_loss: 0.0826 - val_matthews_correlation: 0.6376\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.66459\n",
      "Epoch 14/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.1074 - matthews_correlation: 0.6214 - val_loss: 0.0862 - val_matthews_correlation: 0.6763\n",
      "\n",
      "Epoch 00014: val_matthews_correlation improved from 0.66459 to 0.67629, saving model to weights_2.h5\n",
      "Epoch 15/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.1060 - matthews_correlation: 0.6291 - val_loss: 0.0808 - val_matthews_correlation: 0.6984\n",
      "\n",
      "Epoch 00015: val_matthews_correlation improved from 0.67629 to 0.69836, saving model to weights_2.h5\n",
      "Epoch 16/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.1040 - matthews_correlation: 0.6226 - val_loss: 0.0773 - val_matthews_correlation: 0.6776\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 17/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.1010 - matthews_correlation: 0.6536 - val_loss: 0.0938 - val_matthews_correlation: 0.6525\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 18/40\n",
      "2323/2323 [==============================] - 1s 487us/step - loss: 0.0995 - matthews_correlation: 0.6415 - val_loss: 0.0804 - val_matthews_correlation: 0.6817\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 19/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.1015 - matthews_correlation: 0.6474 - val_loss: 0.0787 - val_matthews_correlation: 0.6808\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 20/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.1064 - matthews_correlation: 0.6599 - val_loss: 0.0826 - val_matthews_correlation: 0.6668\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 21/40\n",
      "2323/2323 [==============================] - 1s 487us/step - loss: 0.0998 - matthews_correlation: 0.6887 - val_loss: 0.0816 - val_matthews_correlation: 0.6658\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 22/40\n",
      "2323/2323 [==============================] - 1s 488us/step - loss: 0.1005 - matthews_correlation: 0.6405 - val_loss: 0.0769 - val_matthews_correlation: 0.6763\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 23/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.0959 - matthews_correlation: 0.6606 - val_loss: 0.0945 - val_matthews_correlation: 0.6592\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 24/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.1011 - matthews_correlation: 0.6321 - val_loss: 0.0899 - val_matthews_correlation: 0.6599\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 25/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.1090 - matthews_correlation: 0.5573 - val_loss: 0.0835 - val_matthews_correlation: 0.6528\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 26/40\n",
      "2323/2323 [==============================] - 1s 480us/step - loss: 0.0983 - matthews_correlation: 0.6429 - val_loss: 0.0799 - val_matthews_correlation: 0.6441\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.69836\n",
      "Epoch 27/40\n",
      "2323/2323 [==============================] - 1s 487us/step - loss: 0.0946 - matthews_correlation: 0.6904 - val_loss: 0.0712 - val_matthews_correlation: 0.7135\n",
      "\n",
      "Epoch 00027: val_matthews_correlation improved from 0.69836 to 0.71353, saving model to weights_2.h5\n",
      "Epoch 28/40\n",
      "2323/2323 [==============================] - 1s 485us/step - loss: 0.0954 - matthews_correlation: 0.7212 - val_loss: 0.0853 - val_matthews_correlation: 0.6720\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 29/40\n",
      "2323/2323 [==============================] - 1s 487us/step - loss: 0.0989 - matthews_correlation: 0.6650 - val_loss: 0.0837 - val_matthews_correlation: 0.6827\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 30/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0922 - matthews_correlation: 0.6874 - val_loss: 0.0801 - val_matthews_correlation: 0.7042\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 31/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0956 - matthews_correlation: 0.6472 - val_loss: 0.0743 - val_matthews_correlation: 0.6711\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 32/40\n",
      "2323/2323 [==============================] - 1s 484us/step - loss: 0.0963 - matthews_correlation: 0.6648 - val_loss: 0.0750 - val_matthews_correlation: 0.6908\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 33/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0889 - matthews_correlation: 0.7103 - val_loss: 0.0722 - val_matthews_correlation: 0.6966\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 34/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.0882 - matthews_correlation: 0.6939 - val_loss: 0.0733 - val_matthews_correlation: 0.7125\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 35/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.0927 - matthews_correlation: 0.6937 - val_loss: 0.0798 - val_matthews_correlation: 0.7076\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.71353\n",
      "Epoch 36/40\n",
      "2323/2323 [==============================] - 1s 486us/step - loss: 0.0992 - matthews_correlation: 0.7160 - val_loss: 0.0861 - val_matthews_correlation: 0.7136\n",
      "\n",
      "Epoch 00036: val_matthews_correlation improved from 0.71353 to 0.71355, saving model to weights_2.h5\n",
      "Epoch 37/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.0918 - matthews_correlation: 0.6639 - val_loss: 0.0702 - val_matthews_correlation: 0.7071\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.71355\n",
      "Epoch 38/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.0887 - matthews_correlation: 0.6629 - val_loss: 0.0777 - val_matthews_correlation: 0.6636\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.71355\n",
      "Epoch 39/40\n",
      "2323/2323 [==============================] - 1s 482us/step - loss: 0.0845 - matthews_correlation: 0.7071 - val_loss: 0.0994 - val_matthews_correlation: 0.6376\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.71355\n",
      "Epoch 40/40\n",
      "2323/2323 [==============================] - 1s 483us/step - loss: 0.0889 - matthews_correlation: 0.7121 - val_loss: 0.0769 - val_matthews_correlation: 0.6571\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.71355\n",
      "Beginning fold 4\n",
      "Train on 2324 samples, validate on 580 samples\n",
      "Epoch 1/40\n",
      "2324/2324 [==============================] - 2s 947us/step - loss: 0.3540 - matthews_correlation: 0.0098 - val_loss: 0.2389 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_3.h5\n",
      "Epoch 2/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.2383 - matthews_correlation: 0.0000e+00 - val_loss: 0.2351 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.2325 - matthews_correlation: 0.0000e+00 - val_loss: 0.2258 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.2300 - matthews_correlation: 0.0000e+00 - val_loss: 0.2240 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.2270 - matthews_correlation: 0.0000e+00 - val_loss: 0.2132 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.2176 - matthews_correlation: 0.0000e+00 - val_loss: 0.2091 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.2069 - matthews_correlation: 0.0000e+00 - val_loss: 0.1830 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 8/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1859 - matthews_correlation: 0.0177 - val_loss: 0.1598 - val_matthews_correlation: 0.2418\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.00000 to 0.24181, saving model to weights_3.h5\n",
      "Epoch 9/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.1625 - matthews_correlation: 0.0636 - val_loss: 0.1678 - val_matthews_correlation: 0.3578\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.24181 to 0.35783, saving model to weights_3.h5\n",
      "Epoch 10/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1468 - matthews_correlation: 0.4364 - val_loss: 0.1579 - val_matthews_correlation: 0.0659\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.35783\n",
      "Epoch 11/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1251 - matthews_correlation: 0.5365 - val_loss: 0.1218 - val_matthews_correlation: 0.5119\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.35783 to 0.51189, saving model to weights_3.h5\n",
      "Epoch 12/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1106 - matthews_correlation: 0.6296 - val_loss: 0.1238 - val_matthews_correlation: 0.4951\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.51189\n",
      "Epoch 13/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1064 - matthews_correlation: 0.5911 - val_loss: 0.1224 - val_matthews_correlation: 0.5528\n",
      "\n",
      "Epoch 00013: val_matthews_correlation improved from 0.51189 to 0.55276, saving model to weights_3.h5\n",
      "Epoch 14/40\n",
      "2324/2324 [==============================] - 1s 479us/step - loss: 0.1033 - matthews_correlation: 0.6507 - val_loss: 0.1232 - val_matthews_correlation: 0.3336\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 15/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1100 - matthews_correlation: 0.5667 - val_loss: 0.1202 - val_matthews_correlation: 0.5370\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 16/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1042 - matthews_correlation: 0.6259 - val_loss: 0.1186 - val_matthews_correlation: 0.3233\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 17/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.1005 - matthews_correlation: 0.6520 - val_loss: 0.1160 - val_matthews_correlation: 0.3894\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 18/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0972 - matthews_correlation: 0.6587 - val_loss: 0.1132 - val_matthews_correlation: 0.4702\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 19/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0957 - matthews_correlation: 0.6434 - val_loss: 0.1132 - val_matthews_correlation: 0.5382\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 20/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0967 - matthews_correlation: 0.6555 - val_loss: 0.1104 - val_matthews_correlation: 0.4892\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 21/40\n",
      "2324/2324 [==============================] - 1s 480us/step - loss: 0.0984 - matthews_correlation: 0.6921 - val_loss: 0.1179 - val_matthews_correlation: 0.5408\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 22/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0944 - matthews_correlation: 0.6491 - val_loss: 0.1141 - val_matthews_correlation: 0.3970\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 23/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0981 - matthews_correlation: 0.6755 - val_loss: 0.1225 - val_matthews_correlation: 0.3951\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 24/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0932 - matthews_correlation: 0.6595 - val_loss: 0.1152 - val_matthews_correlation: 0.5331\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 25/40\n",
      "2324/2324 [==============================] - 1s 478us/step - loss: 0.1030 - matthews_correlation: 0.6695 - val_loss: 0.1281 - val_matthews_correlation: 0.3529\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 26/40\n",
      "2324/2324 [==============================] - 1s 481us/step - loss: 0.0972 - matthews_correlation: 0.6378 - val_loss: 0.1177 - val_matthews_correlation: 0.3362\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.55276\n",
      "Epoch 27/40\n",
      "2324/2324 [==============================] - 1s 477us/step - loss: 0.0965 - matthews_correlation: 0.6820 - val_loss: 0.1178 - val_matthews_correlation: 0.5530\n",
      "\n",
      "Epoch 00027: val_matthews_correlation improved from 0.55276 to 0.55304, saving model to weights_3.h5\n",
      "Epoch 28/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0958 - matthews_correlation: 0.6840 - val_loss: 0.1067 - val_matthews_correlation: 0.5428\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.55304\n",
      "Epoch 29/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0942 - matthews_correlation: 0.6524 - val_loss: 0.1101 - val_matthews_correlation: 0.3880\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.55304\n",
      "Epoch 30/40\n",
      "2324/2324 [==============================] - 1s 472us/step - loss: 0.0955 - matthews_correlation: 0.6838 - val_loss: 0.1045 - val_matthews_correlation: 0.5154\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.55304\n",
      "Epoch 31/40\n",
      "2324/2324 [==============================] - 1s 438us/step - loss: 0.0913 - matthews_correlation: 0.7051 - val_loss: 0.1356 - val_matthews_correlation: 0.4402\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.55304\n",
      "Epoch 32/40\n",
      "2324/2324 [==============================] - 1s 439us/step - loss: 0.0935 - matthews_correlation: 0.6197 - val_loss: 0.1215 - val_matthews_correlation: 0.3983\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.55304\n",
      "Epoch 33/40\n",
      "2324/2324 [==============================] - 1s 441us/step - loss: 0.0984 - matthews_correlation: 0.6938 - val_loss: 0.1098 - val_matthews_correlation: 0.5712\n",
      "\n",
      "Epoch 00033: val_matthews_correlation improved from 0.55304 to 0.57122, saving model to weights_3.h5\n",
      "Epoch 34/40\n",
      "2324/2324 [==============================] - 1s 443us/step - loss: 0.0930 - matthews_correlation: 0.6671 - val_loss: 0.1159 - val_matthews_correlation: 0.5142\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 35/40\n",
      "2324/2324 [==============================] - 1s 442us/step - loss: 0.0966 - matthews_correlation: 0.6435 - val_loss: 0.1109 - val_matthews_correlation: 0.3642\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 36/40\n",
      "2324/2324 [==============================] - 1s 438us/step - loss: 0.1003 - matthews_correlation: 0.6402 - val_loss: 0.1220 - val_matthews_correlation: 0.5054\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 37/40\n",
      "2324/2324 [==============================] - 1s 436us/step - loss: 0.0949 - matthews_correlation: 0.6679 - val_loss: 0.1166 - val_matthews_correlation: 0.5557\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 38/40\n",
      "2324/2324 [==============================] - 1s 441us/step - loss: 0.0931 - matthews_correlation: 0.6648 - val_loss: 0.1188 - val_matthews_correlation: 0.3897\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 39/40\n",
      "2324/2324 [==============================] - 1s 444us/step - loss: 0.0945 - matthews_correlation: 0.6876 - val_loss: 0.1099 - val_matthews_correlation: 0.5296\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.57122\n",
      "Epoch 40/40\n",
      "2324/2324 [==============================] - 1s 469us/step - loss: 0.0861 - matthews_correlation: 0.6894 - val_loss: 0.1255 - val_matthews_correlation: 0.5086\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.57122\n",
      "Beginning fold 5\n",
      "Train on 2324 samples, validate on 580 samples\n",
      "Epoch 1/40\n",
      "2324/2324 [==============================] - 2s 939us/step - loss: 0.3510 - matthews_correlation: 0.0000e+00 - val_loss: 0.2299 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_4.h5\n",
      "Epoch 2/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.2245 - matthews_correlation: 0.0000e+00 - val_loss: 0.2162 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.2029 - matthews_correlation: 0.0000e+00 - val_loss: 0.2017 - val_matthews_correlation: -0.0039\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.1798 - matthews_correlation: 0.0359 - val_loss: 0.1720 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.1898 - matthews_correlation: 0.0000e+00 - val_loss: 0.1780 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1798 - matthews_correlation: 0.0861 - val_loss: 0.2048 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 7/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1810 - matthews_correlation: 0.0788 - val_loss: 0.2092 - val_matthews_correlation: 0.1460\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.00000 to 0.14602, saving model to weights_4.h5\n",
      "Epoch 8/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.1752 - matthews_correlation: 0.2457 - val_loss: 0.1515 - val_matthews_correlation: 0.4042\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.14602 to 0.40424, saving model to weights_4.h5\n",
      "Epoch 9/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.1503 - matthews_correlation: 0.5123 - val_loss: 0.1498 - val_matthews_correlation: 0.4042\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.40424\n",
      "Epoch 10/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.1211 - matthews_correlation: 0.6032 - val_loss: 0.1101 - val_matthews_correlation: 0.4411\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.40424 to 0.44114, saving model to weights_4.h5\n",
      "Epoch 11/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1116 - matthews_correlation: 0.6211 - val_loss: 0.1128 - val_matthews_correlation: 0.6908\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.44114 to 0.69078, saving model to weights_4.h5\n",
      "Epoch 12/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.1099 - matthews_correlation: 0.5862 - val_loss: 0.0979 - val_matthews_correlation: 0.5578\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.69078\n",
      "Epoch 13/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1061 - matthews_correlation: 0.6382 - val_loss: 0.0975 - val_matthews_correlation: 0.6122\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.69078\n",
      "Epoch 14/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1143 - matthews_correlation: 0.5451 - val_loss: 0.0945 - val_matthews_correlation: 0.5703\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.69078\n",
      "Epoch 15/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1029 - matthews_correlation: 0.6191 - val_loss: 0.1080 - val_matthews_correlation: 0.7112\n",
      "\n",
      "Epoch 00015: val_matthews_correlation improved from 0.69078 to 0.71125, saving model to weights_4.h5\n",
      "Epoch 16/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.1090 - matthews_correlation: 0.6008 - val_loss: 0.0935 - val_matthews_correlation: 0.5960\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 17/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0987 - matthews_correlation: 0.6099 - val_loss: 0.0859 - val_matthews_correlation: 0.6822\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 18/40\n",
      "2324/2324 [==============================] - 1s 481us/step - loss: 0.0973 - matthews_correlation: 0.6057 - val_loss: 0.0897 - val_matthews_correlation: 0.5723\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 19/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0983 - matthews_correlation: 0.6066 - val_loss: 0.0858 - val_matthews_correlation: 0.6499\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 20/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0985 - matthews_correlation: 0.5767 - val_loss: 0.0893 - val_matthews_correlation: 0.6093\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 21/40\n",
      "2324/2324 [==============================] - 1s 486us/step - loss: 0.1091 - matthews_correlation: 0.6425 - val_loss: 0.0972 - val_matthews_correlation: 0.5589\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 22/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.1062 - matthews_correlation: 0.5969 - val_loss: 0.0908 - val_matthews_correlation: 0.6204\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 23/40\n",
      "2324/2324 [==============================] - 1s 481us/step - loss: 0.0960 - matthews_correlation: 0.6150 - val_loss: 0.0874 - val_matthews_correlation: 0.6375\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 24/40\n",
      "2324/2324 [==============================] - 1s 481us/step - loss: 0.0957 - matthews_correlation: 0.6877 - val_loss: 0.0856 - val_matthews_correlation: 0.6516\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 25/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0950 - matthews_correlation: 0.6937 - val_loss: 0.0896 - val_matthews_correlation: 0.6357\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 26/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0907 - matthews_correlation: 0.6878 - val_loss: 0.0850 - val_matthews_correlation: 0.6375\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 27/40\n",
      "2324/2324 [==============================] - 1s 481us/step - loss: 0.0904 - matthews_correlation: 0.6726 - val_loss: 0.1004 - val_matthews_correlation: 0.5370\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 28/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0970 - matthews_correlation: 0.6430 - val_loss: 0.0977 - val_matthews_correlation: 0.5865\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 29/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0973 - matthews_correlation: 0.6311 - val_loss: 0.0931 - val_matthews_correlation: 0.5874\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 30/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0883 - matthews_correlation: 0.6807 - val_loss: 0.0858 - val_matthews_correlation: 0.6826\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 31/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0901 - matthews_correlation: 0.7190 - val_loss: 0.0934 - val_matthews_correlation: 0.6674\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 32/40\n",
      "2324/2324 [==============================] - 1s 480us/step - loss: 0.0890 - matthews_correlation: 0.6611 - val_loss: 0.0872 - val_matthews_correlation: 0.6339\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 33/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.0910 - matthews_correlation: 0.6893 - val_loss: 0.0956 - val_matthews_correlation: 0.5953\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 34/40\n",
      "2324/2324 [==============================] - 1s 485us/step - loss: 0.0851 - matthews_correlation: 0.6754 - val_loss: 0.0827 - val_matthews_correlation: 0.6516\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 35/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0933 - matthews_correlation: 0.6523 - val_loss: 0.0914 - val_matthews_correlation: 0.5843\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.71125\n",
      "Epoch 36/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0917 - matthews_correlation: 0.6336 - val_loss: 0.0829 - val_matthews_correlation: 0.7238\n",
      "\n",
      "Epoch 00036: val_matthews_correlation improved from 0.71125 to 0.72384, saving model to weights_4.h5\n",
      "Epoch 37/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0928 - matthews_correlation: 0.6661 - val_loss: 0.0879 - val_matthews_correlation: 0.6093\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.72384\n",
      "Epoch 38/40\n",
      "2324/2324 [==============================] - 1s 482us/step - loss: 0.0919 - matthews_correlation: 0.6689 - val_loss: 0.0883 - val_matthews_correlation: 0.6499\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.72384\n",
      "Epoch 39/40\n",
      "2324/2324 [==============================] - 1s 483us/step - loss: 0.0941 - matthews_correlation: 0.6663 - val_loss: 0.0858 - val_matthews_correlation: 0.6357\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.72384\n",
      "Epoch 40/40\n",
      "2324/2324 [==============================] - 1s 484us/step - loss: 0.0861 - matthews_correlation: 0.6798 - val_loss: 0.0872 - val_matthews_correlation: 0.6093\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.72384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2904,), (2904,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, create a set of indexes of the 5 folds\n",
    "splits = list(StratifiedKFold(n_splits=N_SPLITS,random_state=42).split(X, y))\n",
    "preds_val = []\n",
    "y_val = []\n",
    "# Then, iteract with each fold\n",
    "# If you dont know, enumerate(['a', 'b', 'c']) returns [(0, 'a'), (1, 'b'), (2, 'c')]\n",
    "for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "    K.clear_session() # I dont know what it do, but I imagine that it \"clear session\" :)\n",
    "    print(\"Beginning fold {}\".format(idx+1))\n",
    "    train_X, train_y, val_X, val_y = X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "    model = model_lstm(train_X.shape)\n",
    "    #es = EarlyStopping(monitor='val_matthews_correlation', verbose=2, patience=50, mode='max')\n",
    "    ckpt = ModelCheckpoint('weights_{}.h5'.format(idx), save_best_only=True, save_weights_only=True, verbose=1, monitor='val_matthews_correlation', mode='max')\n",
    "    # Train, train, train\n",
    "    model.fit(train_X, train_y, batch_size=128, epochs=40, validation_data=[val_X, val_y], callbacks=[ckpt])\n",
    "    # loads the best weights saved by the checkpoint\n",
    "    model.load_weights('weights_{}.h5'.format(idx))\n",
    "    # Add the predictions of the validation to the list preds_val\n",
    "    preds_val.append(model.predict(val_X, batch_size=512))\n",
    "    # and the val true y\n",
    "    y_val.append(val_y)\n",
    "\n",
    "# concatenates all and prints the shape    \n",
    "preds_val = np.concatenate(preds_val)[...,0]\n",
    "y_val = np.concatenate(y_val)\n",
    "preds_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "d28151fd0be9fd9762f3f55e307d82f89bfbd291"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
    "        score = K.eval(matthews_correlation(y_true.astype(np.float64), (y_proba > threshold).astype(np.float64)))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'matthews_correlation': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c252624065ee8551ae88a2c10b343e4fee3ecc80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "best_threshold = threshold_search(y_val, preds_val)['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "8fc5b3dceb6f9a2b3882af4342db975c4f487062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ae9bd3fa9d8c0781c0708846bb7f2a9f9e6cbd3c"
   },
   "outputs": [],
   "source": [
    "meta_test = pd.read_csv('../input/metadata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "3eb186d032f79c99ffba05dd1a7fabb77e13cec5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>2904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>2905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_measurement  phase\n",
       "signal_id                       \n",
       "8712                 2904      0\n",
       "8713                 2904      1\n",
       "8714                 2904      2\n",
       "8715                 2905      0\n",
       "8716                 2905      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test = meta_test.set_index(['signal_id'])\n",
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "6f8e94387f625bff0a9a6289e1ee038908bc5856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8712 10 20337 2033 7 20337\n",
      "[[8712, 10745], [10745, 12778], [12778, 14811], [14811, 16844], [16844, 18877], [18877, 20910], [20910, 22943], [22943, 24976], [24976, 27009], [27009, 29042], [29042, 29049]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2033/2033 [02:21<00:00, 14.35it/s]\n",
      "100%|██████████| 2033/2033 [02:25<00:00, 14.15it/s]\n",
      "100%|██████████| 2033/2033 [02:26<00:00, 14.29it/s]\n",
      "100%|██████████| 2033/2033 [02:26<00:00, 14.28it/s]\n",
      "100%|██████████| 2033/2033 [02:27<00:00, 14.13it/s]\n",
      "100%|██████████| 2033/2033 [02:26<00:00, 14.13it/s]\n",
      "100%|██████████| 2033/2033 [02:27<00:00, 14.37it/s]\n",
      "100%|██████████| 2033/2033 [02:26<00:00, 13.86it/s]\n",
      "100%|██████████| 2033/2033 [02:27<00:00, 14.61it/s]\n",
      "100%|██████████| 2033/2033 [02:26<00:00, 14.11it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.57it/s]\n"
     ]
    }
   ],
   "source": [
    "first_sig = meta_test.index[0]\n",
    "n_parts = 10\n",
    "max_line = len(meta_test)\n",
    "part_size = int(max_line / n_parts)\n",
    "last_part = max_line % n_parts\n",
    "print(first_sig, n_parts, max_line, part_size, last_part, n_parts * part_size + last_part)\n",
    "# Here we create a list of lists with start index and end index for each of the 10 parts and one for the last partial part\n",
    "start_end = [[x, x+part_size] for x in range(first_sig, max_line + first_sig, part_size)]\n",
    "start_end = start_end[:-1] + [[start_end[-1][0], start_end[-1][0] + last_part]]\n",
    "print(start_end)\n",
    "X_test = []\n",
    "# now, very like we did above with the train data, we convert the test data part by part\n",
    "# transforming the 3 phases 800000 measurement in matrix (160,57)\n",
    "for start, end in start_end:\n",
    "    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    for i in tqdm(subset_test.columns):\n",
    "        id_measurement, phase = meta_test.loc[int(i)]\n",
    "        subset_test_col = subset_test[i]\n",
    "        subset_trans = transform_ts(subset_test_col)\n",
    "        X_test.append([i, id_measurement, phase, subset_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "af9aa6b2b8f8a2beda1a02ff998e3072fcad8d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 160, 57)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_input = np.asarray([np.concatenate([X_test[i][3],X_test[i+1][3], X_test[i+2][3]], axis=1) for i in range(0,len(X_test), 3)])\n",
    "np.save(\"X_test.npy\",X_test_input)\n",
    "X_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "cfd265d3e07c4cc1679d2c4d55fe7de631c813e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2f7342296138f6bfd3e9cedd029e1035de3b98fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6779/6779 [==============================] - 1s 130us/step\n",
      "6779/6779 [==============================] - 1s 125us/step\n",
      "6779/6779 [==============================] - 1s 125us/step\n",
      "6779/6779 [==============================] - 1s 124us/step\n",
      "6779/6779 [==============================] - 1s 124us/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = []\n",
    "for i in range(N_SPLITS):\n",
    "    model.load_weights('weights_{}.h5'.format(i))\n",
    "    pred = model.predict(X_test_input, batch_size=300, verbose=1)\n",
    "    pred_3 = []\n",
    "    for pred_scalar in pred:\n",
    "        for i in range(3):\n",
    "            pred_3.append(pred_scalar)\n",
    "    preds_test.append(pred_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "4b212616b85a0c704ad8dd11d2ea88c818a4d2a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20337,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = (np.squeeze(np.mean(preds_test, axis=0)) > best_threshold).astype(np.int)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "347a76deca88ff3834c2b372391ada6b30a6ae08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = preds_test\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
